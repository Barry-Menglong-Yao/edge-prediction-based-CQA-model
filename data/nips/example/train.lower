there is experimental evidence that cortical neurons show avalanche activity with the intensity of firing events being distributed as a power-law . <eos> we present a biologically plausible extension of a neural network which exhibits a power-law avalanche distribution for a wide range of connectivity parameters .
we propose an algorithm that uses gaussian process regression to learn common hidden structure shared between corresponding sets of heterogenous observations . <eos> the observation spaces are linked via a single , reduced-dimensionality latent variable space . <eos> we present results from two datasets demonstrating the algorithms ? s ability to synthesize novel data from learned correspondences . <eos> we first show that the method can learn the nonlinear mapping between corresponding views of objects , filling in missing data as needed to synthesize novel views . <eos> we then show that the method can learn a mapping between human degrees of freedom and robotic degrees of freedom for a humanoid robot , allowing robotic imitation of human poses from motion capture data .
experimental data indicate that norepinephrine is critically involved in aspects of vigilance and attention . <eos> previously , we considered the function of this neuromodulatory system on a time scale of minutes and longer , and suggested that it signals global uncertainty arising from gross changes in environmental contingencies . <eos> however , norepinephrine is also known to be activated phasically by familiar stimuli in welllearned tasks . <eos> here , we extend our uncertainty-based treatment of norepinephrine to this phasic mode , proposing that it is involved in the detection and reaction to state uncertainty within a task . <eos> this role of norepinephrine can be understood through the metaphor of neural interrupts .
nested sampling is a new monte carlo method by skilling [ 1 ] intended for general bayesian computation . <eos> nested sampling provides a robust alternative to annealing-based methods for computing normalizing constants . <eos> it can also generate estimates of other quantities such as posterior expectations . <eos> the key technical requirement is an ability to draw samples uniformly from the prior subject to a constraint on the likelihood . <eos> we provide a demonstration with the potts model , an undirected graphical model .
compressed sensing is an emerging field based on the revelation that a small group of linear projections of a sparse signal contains enough information for reconstruction . <eos> in this paper we introduce a new theory for distributed compressed sensing ( dcs ) that enables new distributed coding algorithms for multi-signal ensembles that exploit both intra- and inter-signal correlation structures . <eos> the dcs theory rests on a new concept that we term the joint sparsity of a signal ensemble . <eos> we study three simple models for jointly sparse signals , propose algorithms for joint recovery of multiple signals from incoherent projections , and characterize theoretically and empirically the number of measurements per sensor required for accurate reconstruction . <eos> in some sense dcs is a framework for distributed compression of sources with memory , which has remained a challenging problem in information theory for some time . <eos> dcs is immediately applicable to a range of problems in sensor networks and arrays .
